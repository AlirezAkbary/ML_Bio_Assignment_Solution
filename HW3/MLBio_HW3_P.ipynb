{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efrE1Lc0Otrq"
   },
   "source": [
    "# **Machine Learning in Bioinformatics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtzvENmYOtxi"
   },
   "source": [
    "**Homework 3:**<br/>\n",
    "!!! If you don't fill these fields, your homework does not count !!!<br/>\n",
    "first name and last name :Alireza Akbari<br/>\n",
    "student number : 95105379"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KG3vb72VOt4G"
   },
   "source": [
    "You can run cells by hitting `Shift` + `Enter` or `ctrl` + `Enter`.<br/>\n",
    "We highly recommend you to read each line of code carefully and try to \n",
    "understand what it exactly does.<br/>\n",
    "Just alter the parts that is between green comments and specified for you. <br/>\n",
    "Please do not change other parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:19:17.590995Z",
     "start_time": "2020-04-27T17:19:16.169519Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "v0dotHjRO5x_"
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5C6lgUtO-bg"
   },
   "source": [
    "\n",
    "### about the Data:<br/>\n",
    "The purpose of this project is to classify tumors into malignant or benign. The following dataset is constructed based on images of tumors. Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.\n",
    "For more details about the features of this dataset you can visit this link:\n",
    "https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset<br/>\n",
    "This dataset contains 30 features and 1 label called target.\n",
    "The original dataset labels are 0 and 1 and in the following code boxes we change it to -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:19:22.489227Z",
     "start_time": "2020-04-27T17:19:22.417928Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-7_g8ApcO7tm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890     0.0  \n",
       "1          0.2750                  0.08902     0.0  \n",
       "2          0.3613                  0.08758     0.0  \n",
       "3          0.6638                  0.17300     0.0  \n",
       "4          0.2364                  0.07678     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()  ## change if the data set changed\n",
    "df = pd.DataFrame(np.c_[cancer[\"data\"], cancer[\"target\"]], columns = np.append(cancer[\"feature_names\"],[\"target\"]))\n",
    "features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:19:26.831869Z",
     "start_time": "2020-04-27T17:19:26.807936Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "jmmK95OVPDyg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.94727592267135 %\n",
      "69.94727592267135 %\n",
      "20.035149384885763 %\n",
      "20.035149384885763 %\n",
      "10.017574692442881 %\n",
      "10.017574692442881 %\n"
     ]
    }
   ],
   "source": [
    "cancer.target = np.where(cancer.target==0, -1, cancer.target)\n",
    "X_train ,X_test ,X_val ,y_train ,y_test ,y_val = None ,None ,None ,None ,None ,None\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# 1- Normalize tha data.                                                       #\n",
    "# 2- using train_test_split package, split your data into 3 numpy array        #\n",
    "# called X_train, X_test, and X_val and also split the corresponding labels as #\n",
    "# y_train, y_test, and y_val. After spliting, the ratio of your data should be # \n",
    "# approximately like this:                                                     #\n",
    "#  Train : 70%     test : 20%       validation : 10%                           #\n",
    "################################################################################\n",
    "normalizer = preprocessing.MinMaxScaler()\n",
    "normalized_data = normalizer.fit_transform(cancer.data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_data, cancer.target, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1)\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "print((X_train.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_train.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((X_test.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_test.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((X_val.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_val.shape[0]/cancer.data.shape[0]) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZ3-Fm4uPIdf"
   },
   "source": [
    "# Ensemble Methods\n",
    "\n",
    "## Problem 1. Bagging (15 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:22:31.107213Z",
     "start_time": "2020-04-27T17:22:30.317305Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZzSuFIANPPRh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number 0f Classifiers = 1, Validation Accuracy = 96.491228%\n",
      "Number 0f Classifiers = 3, Validation Accuracy = 98.245614%\n",
      "Number 0f Classifiers = 5, Validation Accuracy = 96.491228%\n",
      "Number 0f Classifiers = 10, Validation Accuracy = 100.000000%\n",
      "Number 0f Classifiers = 20, Validation Accuracy = 100.000000%\n",
      "Number 0f Classifiers = 50, Validation Accuracy = 100.000000%\n",
      "Number 0f Classifiers = 100, Validation Accuracy = 100.000000%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data:\n",
      "97.36842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection \n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "import sklearn\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TODO : initialize the base classifier. You can choose one of the classifiers #\n",
    "# you have learned in this course.(SVM/Decision tree)                          #\n",
    "# IMPORTANT: if you are using SVM as base classifier don't forget to add column#\n",
    "# of '1' s for bias and be careful to use the right datset in next parts.      #\n",
    "################################################################################\n",
    "base_cls = sklearn.svm.SVC()\n",
    "# X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "# X_val = np.insert(X_val, 0, 1, axis=1)\n",
    "# X_test = np.insert(X_test, 0, 1, axis=1)\n",
    "###I have read SKlearn documentation and it says that it handles '1's column for bias. So I commented them\n",
    "##################################################################################\n",
    "# TODO: Number of classifiers is a hyperparameter. Choose it by using validation #\n",
    "# data to have the best accuracy                                                 #\n",
    "# For different number of classifiers, train the model with training data and    #\n",
    "# compute accuracy for validation data. Plot accuracy-number of classifiers plot.#\n",
    "##################################################################################\n",
    "num_cls = [1, 3, 5, 10, 20, 50, 100]\n",
    "seed = 1\n",
    "val_acc_history = []\n",
    "best_model, best_acc = None, 0\n",
    "for num in num_cls:\n",
    "    model = BaggingClassifier(base_estimator = base_cls, \n",
    "                              n_estimators = num, \n",
    "                              random_state = seed)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_val_predict = model.predict(X_val)\n",
    "    current_val_acc = np.mean(y_val == y_val_predict) * 100\n",
    "    val_acc_history.append(current_val_acc)\n",
    "    print('Number 0f Classifiers = %d, Validation Accuracy = %f%%'%(num, current_val_acc))\n",
    "    \n",
    "    if best_acc < current_val_acc:\n",
    "        best_acc = current_val_acc\n",
    "        best_model = model\n",
    "plt.plot(num_cls, val_acc_history, '-bo')\n",
    "plt.show()\n",
    "################################################################################\n",
    "# compute and report the accuracy for test data.                               #\n",
    "################################################################################\n",
    "y_test_predict = best_model.predict(X_test)\n",
    "print(\"Accuracy for test data:\")\n",
    "print(np.mean(y_test == y_test_predict)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELyA0acXgK2w"
   },
   "source": [
    "## Problem 2. Random Forest(25 points)</br>\n",
    "In this part, you should write your own code to classify the data, using random forest from sklearn package in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:30:57.477420Z",
     "start_time": "2020-04-27T17:30:55.905049Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JE4eKUybgQUb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees = 1\n",
      "Maximum Depth of Trees = 1, Validation Accuracy = 92.982456%\n",
      "Maximum Depth of Trees = 3, Validation Accuracy = 98.245614%\n",
      "Maximum Depth of Trees = 5, Validation Accuracy = 96.491228%\n",
      "Maximum Depth of Trees = 8, Validation Accuracy = 96.491228%\n",
      "Maximum Depth of Trees = 10, Validation Accuracy = 96.491228%\n",
      "Maximum Depth of Trees = 20, Validation Accuracy = 96.491228%\n",
      "Maximum Depth of Trees = 30, Validation Accuracy = 96.491228%\n",
      "Number of trees = 3\n",
      "Maximum Depth of Trees = 1, Validation Accuracy = 92.982456%\n",
      "Maximum Depth of Trees = 3, Validation Accuracy = 98.245614%\n",
      "Maximum Depth of Trees = 5, Validation Accuracy = 96.491228%\n",
      "Maximum Depth of Trees = 8, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 10, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 20, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 30, Validation Accuracy = 94.736842%\n",
      "Number of trees = 5\n",
      "Maximum Depth of Trees = 1, Validation Accuracy = 92.982456%\n",
      "Maximum Depth of Trees = 3, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 5, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 8, Validation Accuracy = 91.228070%\n",
      "Maximum Depth of Trees = 10, Validation Accuracy = 91.228070%\n",
      "Maximum Depth of Trees = 20, Validation Accuracy = 91.228070%\n",
      "Maximum Depth of Trees = 30, Validation Accuracy = 91.228070%\n",
      "Number of trees = 8\n",
      "Maximum Depth of Trees = 1, Validation Accuracy = 92.982456%\n",
      "Maximum Depth of Trees = 3, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 5, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 8, Validation Accuracy = 91.228070%\n",
      "Maximum Depth of Trees = 10, Validation Accuracy = 91.228070%\n",
      "Maximum Depth of Trees = 20, Validation Accuracy = 91.228070%\n",
      "Maximum Depth of Trees = 30, Validation Accuracy = 91.228070%\n",
      "Number of trees = 10\n",
      "Maximum Depth of Trees = 1, Validation Accuracy = 91.228070%\n",
      "Maximum Depth of Trees = 3, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 5, Validation Accuracy = 92.982456%\n",
      "Maximum Depth of Trees = 8, Validation Accuracy = 92.982456%\n",
      "Maximum Depth of Trees = 10, Validation Accuracy = 92.982456%\n",
      "Maximum Depth of Trees = 20, Validation Accuracy = 92.982456%\n",
      "Maximum Depth of Trees = 30, Validation Accuracy = 92.982456%\n",
      "Number of trees = 20\n",
      "Maximum Depth of Trees = 1, Validation Accuracy = 91.228070%\n",
      "Maximum Depth of Trees = 3, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 5, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 8, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 10, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 20, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 30, Validation Accuracy = 94.736842%\n",
      "Number of trees = 50\n",
      "Maximum Depth of Trees = 1, Validation Accuracy = 91.228070%\n",
      "Maximum Depth of Trees = 3, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 5, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 8, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 10, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 20, Validation Accuracy = 94.736842%\n",
      "Maximum Depth of Trees = 30, Validation Accuracy = 94.736842%\n",
      "-------------------------------------------------------\n",
      "Precision, recall for test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.88      0.91        42\n",
      "           1       0.93      0.97      0.95        72\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "-------------------------------------------------------\n",
      "Confusion Matrix for test data\n",
      "[[37  5]\n",
      " [ 2 70]]\n",
      "-------------------------------------------------------\n",
      "Accuracy for test data\n",
      "0.9385964912280702\n",
      "-------------------------------------------------------\n",
      "Precision, recall for train data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.94      0.96       151\n",
      "           1       0.96      0.98      0.97       247\n",
      "\n",
      "    accuracy                           0.97       398\n",
      "   macro avg       0.97      0.96      0.97       398\n",
      "weighted avg       0.97      0.97      0.97       398\n",
      "\n",
      "-------------------------------------------------------\n",
      "Confusion Matrix for train data\n",
      "[[142   9]\n",
      " [  4 243]]\n",
      "-------------------------------------------------------\n",
      "Accuracy for test data\n",
      "0.9673366834170855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "#################################################################################\n",
    "# TODO:use the validation data to determine hyperparameters(number and depth of #\n",
    "# trees) for the best accuracy                                                  # \n",
    "#################################################################################\n",
    "num_trees = [1, 3, 5, 8, 10, 20, 50]\n",
    "max_depths = [1, 3, 5, 8, 10, 20, 30]\n",
    "\n",
    "best_model, best_acc = None, 0\n",
    "for num_tree in num_trees:\n",
    "    print(\"Number of trees = %d\"%(num_tree))\n",
    "    for max_depth in max_depths:\n",
    "        model = RandomForestClassifier(n_estimators=num_tree, max_depth=max_depth, random_state=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_val_predict = model.predict(X_val)\n",
    "        current_val_acc = np.mean(y_val == y_val_predict)*100\n",
    "        print(\"Maximum Depth of Trees = %d, Validation Accuracy = %f%%\"%(max_depth, current_val_acc))\n",
    "        \n",
    "        if best_acc <= current_val_acc:\n",
    "            best_acc = current_val_acc\n",
    "            best_model = model\n",
    "\n",
    "#######################################################################################\n",
    "#TODO:report accuracy, presition,recall and confusion matrix for train and test data  #\n",
    "#######################################################################################\n",
    "y_test_predict = best_model.predict(X_test)\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Precision, recall for test data\")\n",
    "print(classification_report(y_test, y_test_predict))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Confusion Matrix for test data\")\n",
    "print(confusion_matrix(y_test, y_test_predict))\n",
    "\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Accuracy for test data\")\n",
    "print(accuracy_score(y_test, y_test_predict))\n",
    "\n",
    "y_train_predict = best_model.predict(X_train)\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Precision, recall for train data\")\n",
    "print(classification_report(y_train, y_train_predict))\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Confusion Matrix for train data\")\n",
    "print(confusion_matrix(y_train, y_train_predict))\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Accuracy for test data\")\n",
    "print(accuracy_score(y_train, y_train_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pSr7G0fdgmyf"
   },
   "source": [
    "Question:\n",
    "Explain how you did choose the hyperparameters.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br/>\n",
    "<div id=\"sec_conclusion\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "        با توجه به آنکه دیتا ولیدیشن از پیش موجود است از تکنیک \n",
    "        d-fold \n",
    "        ولیدیشن استفاده نمی‌کنیم. اینجا مقادیری را برای دو هایپرپارامتر بیشترین عمق و تعداد درخت‌ها در نظر می‌گیریم. حال به ازای مقادیر مختلف آن‌ها \n",
    "        search \n",
    "        می‌کنیم و هر بار مدل را با یکی از گزینه‌ها ترین می‌کنیم. سپس مدل را روی داده ولیدیشن تست می‌کنیم. و در نهایت آن گزینه‌ای که بیشترین دقت را روی داده ولیدیشن دارد به عنوان هایپرپارامتر در نظر می‌گیریم. چون این کار را روی داده ولیددیشن انجام دادیم، منجر به \n",
    "        overfitting\n",
    "        نمی‌شود.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fxpbM42MPg6m"
   },
   "source": [
    "## Problem 3. Boosting : AdaBoost (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rUodQdBvPrKQ"
   },
   "source": [
    "In this part you should implement adaptive boosting algorithm. </br>\n",
    "<picture>\n",
    "  <img src=\"http://uupload.ir/files/b919_adaboost.png\" alt=\"Adaboost\" width=\"600\" height=\"300\">\n",
    "</picture>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:59:40.634435Z",
     "start_time": "2020-04-27T17:59:40.599685Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "r9TL5FGqRIoL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data accuracy is: 89.8901098901099 %\n",
      "The test data accuracy is: 86.8421052631579 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "X_train ,X_test ,y_train ,y_test = None ,None ,None ,None\n",
    "###################################################################\n",
    "# TODO: use 80% of normalized data as train and 20% as test data. #\n",
    "###################################################################\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_data, cancer.target, test_size=0.2, random_state=1)\n",
    "\n",
    "######################################################################\n",
    "#TODO : define a weak decision tree.                                 #\n",
    "# initialize these parameters: criterion=\"entropy\" and max_depth = 1 #\n",
    "######################################################################\n",
    "Tree_model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=1)\n",
    "#############################################################################################\n",
    "#TODO : report accuracy of your weak model on train and test data by using cross validation #\n",
    "#############################################################################################\n",
    "train_accuracy = np.mean(cross_validate(Tree_model, X_train, y_train)['test_score']) \n",
    "print('The training data accuracy is:' ,train_accuracy * 100 , '%')\n",
    "\n",
    "Tree_model.fit(X_train, y_train)\n",
    "y_test_predict = Tree_model.predict(X_test)\n",
    "print('The test data accuracy is:' ,np.mean(y_test == y_test_predict) * 100 , '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:59:50.380770Z",
     "start_time": "2020-04-27T17:59:50.359400Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "elsmjgbNRSdH"
   },
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    \n",
    "    def __init__(self,train_data_X,train_data_y,tree_num,test_data_X,test_data_y):\n",
    "        self.train_data_X = train_data_X\n",
    "        self.train_data_y = train_data_y\n",
    "        self.tree_num = tree_num\n",
    "        self.test_data_X = test_data_X\n",
    "        self.test_data_y = test_data_y\n",
    "        self.alphas = None\n",
    "        self.models = None\n",
    "        self.accuracy = []\n",
    "        self.predictions = None\n",
    "        \n",
    "    def fit(self):\n",
    "        Evaluation = pd.DataFrame(self.train_data_y.copy())\n",
    "        Evaluation.columns = ['target']\n",
    "        \n",
    "        ## TODO:Set the initial weights w = 1/N\n",
    "        Evaluation['weights'] = (1/self.train_data_X.shape[0]) * np.ones(self.train_data_X.shape[0]) \n",
    "        \n",
    "        alphas = [] #list of alphas \n",
    "        models = [] # list of trained models\n",
    "        for t in range(self.tree_num):\n",
    "\n",
    "            ## TODO: create a weak decisiontree classifier\n",
    "            Tree_model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=1)\n",
    "            ## TODO: fit the model with train data. set the sample_weight parameter to the 'weights' columns in Evaluation dataframe\n",
    "            model = Tree_model.fit(self.train_data_X, self.train_data_y, sample_weight=Evaluation['weights']) \n",
    "            \n",
    "            models.append(model)\n",
    "            predictions = model.predict(self.train_data_X)\n",
    "            score = model.score(self.train_data_X,self.train_data_y)\n",
    "\n",
    "            ## Add this columns to the Evaluation DataFrame\n",
    "            Evaluation['predictions'] = predictions\n",
    "            ## TODO: In each row if the prediction and the target are equal,this column must be '1' and '0' O.W. \n",
    "            Evaluation['evaluation'] = (Evaluation['target'] == predictions).astype(int)\n",
    "            ## TODO: In each row if the tha data is missclassified, this column must be 1.\n",
    "            Evaluation['misclassified'] = (Evaluation['target'] != predictions).astype(int)\n",
    "\n",
    "            ## TODO: Calculate the misclassification rate and accuracy and then use them to calculate error\n",
    "            accuracy = np.sum(Evaluation['evaluation'] * Evaluation['weights']) \n",
    "            misclassification = 1 - accuracy\n",
    "            err = misclassification\n",
    "\n",
    "            ## TODO: Calculate the alpha values from the adaboost algorithm\n",
    "            alpha = np.log((1/err) - 1) / 2\n",
    "            alphas.append(alpha)\n",
    "            ## TODO: update the weights\n",
    "            Evaluation['weights'] = Evaluation['weights'] * np.exp(-1*alpha*Evaluation['predictions']*Evaluation['target'])\n",
    "            Evaluation['weights'] = Evaluation['weights'] / (np.sum(Evaluation['weights']))\n",
    "\n",
    "        self.alphas = alphas\n",
    "        self.models = models\n",
    "        \n",
    "        \n",
    "    def predict(self):\n",
    "        \n",
    "        accuracy = []\n",
    "        predictions = []\n",
    "        cache = []\n",
    "        #####################################################################################\n",
    "        #TODO:                                                                              #\n",
    "        # 1- predict target for test data and append each prediction to the predictions list#\n",
    "        # 2- Create a list of accuracies which can be used to plot the accuracy against the #\n",
    "        # number of base learners used for the model                                        #\n",
    "        #####################################################################################\n",
    "        for alpha,model in zip(self.alphas,self.models):\n",
    "            \n",
    "            current_cache = alpha * model.predict(self.test_data_X)\n",
    "            cache.append(current_cache)\n",
    "            prediction = np.sign(np.sum(np.array(cache), axis=0))\n",
    "            predictions.append(prediction)\n",
    "            self.accuracy.append(np.mean(prediction == self.test_data_y))\n",
    "            #print(alpha, model)\n",
    "\n",
    "            \n",
    "        self.predictions = np.sign(np.sum(np.array(predictions),axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:03:01.394908Z",
     "start_time": "2020-04-27T18:02:59.905528Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-by9WfOXRVQG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a number of  100 base models we receive an accuracy of  100.0 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On test data,With a number of  100 base models we receive an accuracy of  95.6140350877193 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy - number of base learners plot for training data\n",
    "\n",
    "number_of_base_learners = 100\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax0 = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "\n",
    "model = AdaBoost(X_train,y_train,number_of_base_learners,X_train,y_train)\n",
    "model.fit()\n",
    "model.predict()\n",
    "\n",
    "ax0.plot(range(len(model.accuracy)),model.accuracy,'-b')\n",
    "ax0.set_xlabel('# models used for Boosting ')\n",
    "ax0.set_ylabel('accuracy')\n",
    "print('With a number of ',number_of_base_learners,'base models we receive an accuracy of ',model.accuracy[-1]*100,'%')    \n",
    "                 \n",
    "plt.show()   \n",
    "#################################################################### \n",
    "# TODO: Plot Accuracy - number of base learners plot for test data #\n",
    "####################################################################  \n",
    "model = AdaBoost(X_train,y_train,number_of_base_learners,X_test,y_test)\n",
    "model.fit()\n",
    "model.predict()\n",
    "plt.plot(range(len(model.accuracy)),model.accuracy,'-b')\n",
    "plt.xlabel('# models used for Boosting on test data')\n",
    "plt.ylabel('accuracy')\n",
    "print('On test data,With a number of ',number_of_base_learners,'base models we receive an accuracy of ',model.accuracy[-1]*100,'%')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHIp-4p9Ravu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2olecphWRi4L"
   },
   "source": [
    "# Feature Selction </br>\n",
    "\n",
    "## problem4. Filtering : correlation coefficient (25 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:04:02.287901Z",
     "start_time": "2020-04-27T18:04:02.273574Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "oe0ynxveRmXS",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius               -0.730029\n",
       "mean texture              -0.415185\n",
       "mean perimeter            -0.742636\n",
       "mean area                 -0.708984\n",
       "mean smoothness           -0.358560\n",
       "mean compactness          -0.596534\n",
       "mean concavity            -0.696360\n",
       "mean concave points       -0.776614\n",
       "mean symmetry             -0.330499\n",
       "mean fractal dimension     0.012838\n",
       "radius error              -0.567134\n",
       "texture error              0.008303\n",
       "perimeter error           -0.556141\n",
       "area error                -0.548236\n",
       "smoothness error           0.067016\n",
       "compactness error         -0.292999\n",
       "concavity error           -0.253730\n",
       "concave points error      -0.408042\n",
       "symmetry error             0.006522\n",
       "fractal dimension error   -0.077972\n",
       "worst radius              -0.776454\n",
       "worst texture             -0.456903\n",
       "worst perimeter           -0.782914\n",
       "worst area                -0.733825\n",
       "worst smoothness          -0.421465\n",
       "worst compactness         -0.590998\n",
       "worst concavity           -0.659610\n",
       "worst concave points      -0.793566\n",
       "worst symmetry            -0.416294\n",
       "worst fractal dimension   -0.323872\n",
       "target                     1.000000\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################# \n",
    "# TODO:                                                                         #\n",
    "# use 80% of normalized data as train and 20% as test data.(just use the data   # \n",
    "# from last part)                                                               #\n",
    "# 1- compute the correlation coefficient between each feature and target.       #\n",
    "# 2- Report the features that their correlation is more than 0.5                #\n",
    "# 3- compute the correlation between the features you reported in 2nd           #\n",
    "# section and report features that their correlation with other features        #\n",
    "# is less than 0.5                                                              #\n",
    "# 4- use perceptron from sklearn package to classify the data. Report accurracy #\n",
    "# for test data and sort the features based on their weights in perceptron.     #\n",
    "# IMPORTANT: Don't forget to add 1s to the end of feature vectors to be         #\n",
    "# multiplied by bias term of weight in perceptron.                              #\n",
    "# 5- compare the features you reported in section 2 and 3 with the features     #\n",
    "# that have the most weights in perceptron and write your analysis below        #\n",
    "# 6 - Classify data with perceptron and use only the features you repoted in    # \n",
    "# section 2 and report accuracy for test data.                                  #\n",
    "# 7 - Do the same with section 3 and compare accuracies.                        #\n",
    "#################################################################################\n",
    "\n",
    "#Part one\n",
    "df.corr()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:05:14.390061Z",
     "start_time": "2020-04-27T18:05:14.372137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features that their correlation is more than 0.5 with target:\n",
      "['worst concave points', 'worst perimeter', 'mean concave points', 'worst radius', 'mean perimeter', 'worst area', 'mean radius', 'mean area', 'mean concavity', 'worst concavity', 'mean compactness', 'worst compactness', 'radius error', 'perimeter error', 'area error']\n",
      "\n",
      "Index of features that their correlation is more than 0.5 with target:\n",
      "[27, 22, 7, 20, 2, 23, 0, 3, 6, 26, 5, 25, 10, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "#Part two\n",
    "df['target'] = np.where(cancer.target==0, -1, cancer.target)\n",
    "the_features = (abs(df.corr()['target']).sort_values(ascending=False) > 0.5)\n",
    "the_features = the_features.loc[the_features==True].index.tolist()[1:]\n",
    "print(\"Features that their correlation is more than 0.5 with target:\")\n",
    "print(the_features)\n",
    "the_features_index = []\n",
    "for i in the_features:\n",
    "    the_features_index.append(df.columns.get_loc(i))\n",
    "\n",
    "\n",
    "print()    \n",
    "print(\"Index of features that their correlation is more than 0.5 with target:\")\n",
    "print(the_features_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:05:24.225752Z",
     "start_time": "2020-04-27T18:05:24.183786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>radius error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>worst concave points</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>0.910155</td>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.855434</td>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.531062</td>\n",
       "      <td>0.554897</td>\n",
       "      <td>0.538166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst perimeter</th>\n",
       "      <td>0.816322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>0.993708</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.959120</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>0.719684</td>\n",
       "      <td>0.721031</td>\n",
       "      <td>0.761213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concave points</th>\n",
       "      <td>0.910155</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830318</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.698050</td>\n",
       "      <td>0.710650</td>\n",
       "      <td>0.690299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst radius</th>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.993708</td>\n",
       "      <td>0.830318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969476</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.969539</td>\n",
       "      <td>0.962746</td>\n",
       "      <td>0.688236</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.475820</td>\n",
       "      <td>0.715065</td>\n",
       "      <td>0.697201</td>\n",
       "      <td>0.757373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean perimeter</th>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.969476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941550</td>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.691765</td>\n",
       "      <td>0.693135</td>\n",
       "      <td>0.744983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst area</th>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.941550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.675987</td>\n",
       "      <td>0.543331</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.438296</td>\n",
       "      <td>0.751548</td>\n",
       "      <td>0.730713</td>\n",
       "      <td>0.811408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean radius</th>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.969539</td>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.941082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.679090</td>\n",
       "      <td>0.674172</td>\n",
       "      <td>0.735864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean area</th>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.959120</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.962746</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.498502</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.732562</td>\n",
       "      <td>0.726628</td>\n",
       "      <td>0.800086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concavity</th>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>0.688236</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.675987</td>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>0.754968</td>\n",
       "      <td>0.631925</td>\n",
       "      <td>0.660391</td>\n",
       "      <td>0.617427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concavity</th>\n",
       "      <td>0.855434</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.543331</td>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>0.380585</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.385100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean compactness</th>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.498502</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865809</td>\n",
       "      <td>0.497473</td>\n",
       "      <td>0.548905</td>\n",
       "      <td>0.455653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst compactness</th>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.475820</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.438296</td>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.754968</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>0.865809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287103</td>\n",
       "      <td>0.341919</td>\n",
       "      <td>0.283257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius error</th>\n",
       "      <td>0.531062</td>\n",
       "      <td>0.719684</td>\n",
       "      <td>0.698050</td>\n",
       "      <td>0.715065</td>\n",
       "      <td>0.691765</td>\n",
       "      <td>0.751548</td>\n",
       "      <td>0.679090</td>\n",
       "      <td>0.732562</td>\n",
       "      <td>0.631925</td>\n",
       "      <td>0.380585</td>\n",
       "      <td>0.497473</td>\n",
       "      <td>0.287103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972794</td>\n",
       "      <td>0.951830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter error</th>\n",
       "      <td>0.554897</td>\n",
       "      <td>0.721031</td>\n",
       "      <td>0.710650</td>\n",
       "      <td>0.697201</td>\n",
       "      <td>0.693135</td>\n",
       "      <td>0.730713</td>\n",
       "      <td>0.674172</td>\n",
       "      <td>0.726628</td>\n",
       "      <td>0.660391</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.548905</td>\n",
       "      <td>0.341919</td>\n",
       "      <td>0.972794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area error</th>\n",
       "      <td>0.538166</td>\n",
       "      <td>0.761213</td>\n",
       "      <td>0.690299</td>\n",
       "      <td>0.757373</td>\n",
       "      <td>0.744983</td>\n",
       "      <td>0.811408</td>\n",
       "      <td>0.735864</td>\n",
       "      <td>0.800086</td>\n",
       "      <td>0.617427</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.455653</td>\n",
       "      <td>0.283257</td>\n",
       "      <td>0.951830</td>\n",
       "      <td>0.937655</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      worst concave points  worst perimeter  \\\n",
       "worst concave points              1.000000         0.816322   \n",
       "worst perimeter                   0.816322         1.000000   \n",
       "mean concave points               0.910155         0.855923   \n",
       "worst radius                      0.787424         0.993708   \n",
       "mean perimeter                    0.771241         0.970387   \n",
       "worst area                        0.747419         0.977578   \n",
       "mean radius                       0.744214         0.965137   \n",
       "mean area                         0.722017         0.959120   \n",
       "mean concavity                    0.861323         0.729565   \n",
       "worst concavity                   0.855434         0.618344   \n",
       "mean compactness                  0.815573         0.590210   \n",
       "worst compactness                 0.801080         0.529408   \n",
       "radius error                      0.531062         0.719684   \n",
       "perimeter error                   0.554897         0.721031   \n",
       "area error                        0.538166         0.761213   \n",
       "\n",
       "                      mean concave points  worst radius  mean perimeter  \\\n",
       "worst concave points             0.910155      0.787424        0.771241   \n",
       "worst perimeter                  0.855923      0.993708        0.970387   \n",
       "mean concave points              1.000000      0.830318        0.850977   \n",
       "worst radius                     0.830318      1.000000        0.969476   \n",
       "mean perimeter                   0.850977      0.969476        1.000000   \n",
       "worst area                       0.809630      0.984015        0.941550   \n",
       "mean radius                      0.822529      0.969539        0.997855   \n",
       "mean area                        0.823269      0.962746        0.986507   \n",
       "mean concavity                   0.921391      0.688236        0.716136   \n",
       "worst concavity                  0.752399      0.573975        0.563879   \n",
       "mean compactness                 0.831135      0.535315        0.556936   \n",
       "worst compactness                0.667454      0.475820        0.455774   \n",
       "radius error                     0.698050      0.715065        0.691765   \n",
       "perimeter error                  0.710650      0.697201        0.693135   \n",
       "area error                       0.690299      0.757373        0.744983   \n",
       "\n",
       "                      worst area  mean radius  mean area  mean concavity  \\\n",
       "worst concave points    0.747419     0.744214   0.722017        0.861323   \n",
       "worst perimeter         0.977578     0.965137   0.959120        0.729565   \n",
       "mean concave points     0.809630     0.822529   0.823269        0.921391   \n",
       "worst radius            0.984015     0.969539   0.962746        0.688236   \n",
       "mean perimeter          0.941550     0.997855   0.986507        0.716136   \n",
       "worst area              1.000000     0.941082   0.959213        0.675987   \n",
       "mean radius             0.941082     1.000000   0.987357        0.676764   \n",
       "mean area               0.959213     0.987357   1.000000        0.685983   \n",
       "mean concavity          0.675987     0.676764   0.685983        1.000000   \n",
       "worst concavity         0.543331     0.526911   0.512606        0.884103   \n",
       "mean compactness        0.509604     0.506124   0.498502        0.883121   \n",
       "worst compactness       0.438296     0.413463   0.390410        0.754968   \n",
       "radius error            0.751548     0.679090   0.732562        0.631925   \n",
       "perimeter error         0.730713     0.674172   0.726628        0.660391   \n",
       "area error              0.811408     0.735864   0.800086        0.617427   \n",
       "\n",
       "                      worst concavity  mean compactness  worst compactness  \\\n",
       "worst concave points         0.855434          0.815573           0.801080   \n",
       "worst perimeter              0.618344          0.590210           0.529408   \n",
       "mean concave points          0.752399          0.831135           0.667454   \n",
       "worst radius                 0.573975          0.535315           0.475820   \n",
       "mean perimeter               0.563879          0.556936           0.455774   \n",
       "worst area                   0.543331          0.509604           0.438296   \n",
       "mean radius                  0.526911          0.506124           0.413463   \n",
       "mean area                    0.512606          0.498502           0.390410   \n",
       "mean concavity               0.884103          0.883121           0.754968   \n",
       "worst concavity              1.000000          0.816275           0.892261   \n",
       "mean compactness             0.816275          1.000000           0.865809   \n",
       "worst compactness            0.892261          0.865809           1.000000   \n",
       "radius error                 0.380585          0.497473           0.287103   \n",
       "perimeter error              0.418899          0.548905           0.341919   \n",
       "area error                   0.385100          0.455653           0.283257   \n",
       "\n",
       "                      radius error  perimeter error  area error  \n",
       "worst concave points      0.531062         0.554897    0.538166  \n",
       "worst perimeter           0.719684         0.721031    0.761213  \n",
       "mean concave points       0.698050         0.710650    0.690299  \n",
       "worst radius              0.715065         0.697201    0.757373  \n",
       "mean perimeter            0.691765         0.693135    0.744983  \n",
       "worst area                0.751548         0.730713    0.811408  \n",
       "mean radius               0.679090         0.674172    0.735864  \n",
       "mean area                 0.732562         0.726628    0.800086  \n",
       "mean concavity            0.631925         0.660391    0.617427  \n",
       "worst concavity           0.380585         0.418899    0.385100  \n",
       "mean compactness          0.497473         0.548905    0.455653  \n",
       "worst compactness         0.287103         0.341919    0.283257  \n",
       "radius error              1.000000         0.972794    0.951830  \n",
       "perimeter error           0.972794         1.000000    0.937655  \n",
       "area error                0.951830         0.937655    1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part three\n",
    "df[the_features].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:10:08.423551Z",
     "start_time": "2020-04-27T18:10:08.409336Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features that have less than 0.5 correlation with some of other features the most\n",
      "['worst concavity', 'mean compactness', 'worst compactness', 'radius error', 'area error']\n",
      "\n",
      "Index of features that have less than 0.5 correlation with some of other features the most\n",
      "[26, 5, 25, 10, 13]\n"
     ]
    }
   ],
   "source": [
    "#Part three\n",
    "df_cor = abs(df[the_features].corr())\n",
    "df_cor = ((df_cor<0.5).sum() >= 3)\n",
    "final_features = df_cor[df_cor == True].index.tolist()\n",
    "print(\"Features that have less than 0.5 correlation with some of other features the most\")\n",
    "print(final_features)\n",
    "final_features_index = []\n",
    "for i in final_features:\n",
    "    final_features_index.append(df.columns.get_loc(i))\n",
    "final_features_index = final_features_index\n",
    "print()\n",
    "print(\"Index of features that have less than 0.5 correlation with some of other features the most\")\n",
    "print(final_features_index)\n",
    "final_features_index = final_features_index[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:09:58.559781Z",
     "start_time": "2020-04-27T18:09:58.546672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of perceptron with all features\n",
      "0.9649122807017544\n",
      "\n",
      "Sort features based on their weights\n",
      "[ 7 21 20  6 23 10 22 27 24  9 28 12 26 13  1 15 14 19  3 11 29  5  8 16\n",
      " 25  2 17 18  0  4]\n"
     ]
    }
   ],
   "source": [
    "#Part four\n",
    "from sklearn.linear_model import Perceptron\n",
    "the_model = Perceptron()\n",
    "the_model.fit(X_train, y_train)\n",
    "print(\"Accuracy of perceptron with all features\")\n",
    "print(the_model.score(X_test, y_test))\n",
    "print()\n",
    "print(\"Sort features based on their weights in perceptron with all features\")\n",
    "print(np.argsort(np.abs(the_model.coef_[0])[:30])[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:10:00.878033Z",
     "start_time": "2020-04-27T18:10:00.867779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8859649122807017\n"
     ]
    }
   ],
   "source": [
    "#Part 6\n",
    "the_model = Perceptron()\n",
    "the_model.fit(X_train[:, the_features_index], y_train)\n",
    "print(the_model.score(X_test[:, the_features_index], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T18:10:11.537846Z",
     "start_time": "2020-04-27T18:10:11.527446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8859649122807017\n"
     ]
    }
   ],
   "source": [
    "#Part 7\n",
    "the_model = Perceptron()\n",
    "the_model.fit(X_train[:, final_features_index], y_train)\n",
    "print(the_model.score(X_test[:, final_features_index], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o0QJrI36-GNR"
   },
   "source": [
    "explanation of part 5 and 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTC2KZ1h-QO6"
   },
   "source": [
    "<p></p>\n",
    "<br/>\n",
    "<div id=\"sec_conclusion\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "اهمیت وزن‌های بدست‌آمده در پرسپترون به ترتیب عبارت است از:\n",
    "        <p dir='ltr'>\n",
    "[ 7 21 20  6 23 10 22 27 24  9 28 12 26 13  1 15 14 19  3 11 29  5  8 1625  2 17 18  0  4]\n",
    "            </p>\n",
    "            فیچرهای بدست‌آمده در بخش دوم عبارتند از:\n",
    "            <p dir='ltr'>\n",
    "                [27, 22, 7, 20, 2, 23, 0, 3, 6, 26, 5, 25, 10, 12, 13]\n",
    "        </p>\n",
    "        و فیچرهای بدست‌آ«ده در بخش سوم عبارتند از:\n",
    "        <p dir='ltr'>\n",
    "            [26, 5, 25, 10, 13]\n",
    "        </p>\n",
    "        علت آنکه بیشتر از سه تا هستند این است که یک سری‌شان به تعداد مساوی با دیگر فیچرها کوریلیشن کمتر از ۰.۵ داشتند.\n",
    "        <br>\n",
    "        یک سری از فیچرهایی که در قسمت دوم انتخاب شده‌اند، از فیچرهای مهم در الگوریتم پرسپترون بوده‌اند. این حاکی از آن است که این فیچرها به طور کلی ویژگی‌های مهمی بوده‌اند که در دسته‌بندی داده به خوبی‌کمک می‌توانند بکنند. اما هم در فیچرهای قسمت دو و بخصوص در فیچرهای قسمت سه، می‌بینیم که فیچرها مطابقت چندانی ندارند. یکی از مشکلات روش فیلتر هم در واقع همین است که این روش با نادیده گرفتن \n",
    "        inductive bias\n",
    "        یک الگوریتم خاص، تنها فیچرهای با وابستگی خطی بالا را در نظر می‌گیرد. در حالی که می‌دانیم یادگیری بدون \n",
    "        inductive bias\n",
    "        عملا امکان‌پذیر نیست. در نتیجه فیچرها مطابقت زیادی با \n",
    "        inductive bias\n",
    "        الگوریتم پرسپترون نداشته‌اند. از طرفی تعداد ویژگی‌ها ۳۰ عدد است که تعداد زیادی محسوب نمی‌شود و در نتیجه استفاده از تکنیک انتخاب ویژگی لزوما نمی‌تواند کمک بزرگی به یادگیری انجام دهد.\n",
    "        در نتیجه دقت یادگیری با فیچرهای انتخاب شده کاهش یافته است. اما همچنان دقت نسبتا خوبی را تولید می‌کند.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_XG0iKSRqnE"
   },
   "source": [
    "Question: Is it important to extract features before classifying using methods like decision tree and SVM? why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ro6v3JSBRsd5"
   },
   "source": [
    "می‌تواند منجر به این شود که \n",
    "\n",
    "overfitting\n",
    "\n",
    "اتفاق نیفتد. چرا که مدل‌های کمتر پیچیده‌ای می‌تواند به خود بگیرد.\n",
    "همچنین استفاده کردن از بخشی از فیچرها در حالتی که دیتاست بسیار بزرگ باشد می‌تواند به سرعت یادگیری کمک کند"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQjRm5a6j8KZ"
   },
   "source": [
    "## problem 5. mRMR (10 bonus points) </br>\n",
    "In this part you should write your own code and classify the data using mRMR method.You can use \"pymrmr\" package for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQs-LPupRoDx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLBio_HW3_P.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
